{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243e00eb-11ae-42f5-ba18-49b6e0936fbc",
   "metadata": {},
   "source": [
    "## Identify the mode of the given images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615d17db-663c-48f0-931e-4337c9dad1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I;16B\n"
     ]
    }
   ],
   "source": [
    "image= Image.open(\"./images/disc.tif\")\n",
    "mode = image.mode\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb296de-110b-447a-b2cc-944d46b4f909",
   "metadata": {},
   "source": [
    "## Code to generate Random Images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af89f38-22cf-4800-af07-b4bc511aecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test2.py\n",
    "\n",
    "#python3 gen_images.py --input input_images/ --out-dims 1024 1024 --nout 1000 --output output_images/\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from PIL import Image\n",
    "\n",
    "def generate_images(input_folder, M, output_folder, nout):\n",
    "    # Checking if the input folder exists\n",
    "    if not os.path.isdir(input_folder):\n",
    "        print(f\"Input folder {input_folder} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Creating output folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Reading 4 images from the input folder\n",
    "    input_images = [Image.open(os.path.join(input_folder, file)).convert('I') for file in os.listdir(input_folder) if file.endswith('.tif')]\n",
    "    N = len(input_images)\n",
    "\n",
    "    # Computing k based on the input image sizes and M\n",
    "    k = M // max([max(img.size) for img in input_images])\n",
    "\n",
    "    for i in range(nout):\n",
    "        # Generating M x M pixel output images in I mode\n",
    "        output_image = Image.new('I', (M, M))\n",
    "\n",
    "        # List to store the positions and sizes of all images that have been placed\n",
    "        placed_images = []\n",
    "\n",
    "        for j in range(N):\n",
    "            for _ in range(k):\n",
    "                # Scaling each shape randomly by a factor of 1 to 0.75\n",
    "                scale_factor = random.uniform(0.75, 1)\n",
    "                img = input_images[j].resize((int(input_images[j].width * scale_factor), int(input_images[j].height * scale_factor)))\n",
    "\n",
    "                # Rotating each shape randomly by 0 to 90 degrees\n",
    "                img = img.rotate(random.uniform(0, 90))\n",
    "\n",
    "                #Placing the shapes at random position without getting cut off at the boundary or overlap other shapes\n",
    "                for _ in range(100):  # Try up to 100 times\n",
    "                    max_x = M - img.width\n",
    "                    max_y = M - img.height\n",
    "                    pos_x = random.randint(0, max_x)\n",
    "                    pos_y = random.randint(0, max_y)\n",
    "\n",
    "                    # Checking if this position overlaps with any existing shapes\n",
    "                    if any((pos_x < x + w and pos_x + img.width > x and pos_y < y + h and pos_y + img.height > y) for x, y, w, h in placed_images):\n",
    "                        continue  # This position overlaps\n",
    "\n",
    "                    # This position does not overlap, placing the shape here\n",
    "                    output_image.paste(img, (pos_x, pos_y))\n",
    "                    placed_images.append((pos_x, pos_y, img.width, img.height))\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Could not place image {j} after 100 attempts. Skipping this image.\")\n",
    "\n",
    "        # Save the output image\n",
    "        output_image.save(os.path.join(output_folder, f'output_{i}.png'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Generate images.')\n",
    "    parser.add_argument('--input', type=str, required=True, help='Input folder')\n",
    "    parser.add_argument('--out-dims', type=int, nargs=2, required=True, help='Output image dimensions')\n",
    "    parser.add_argument('--nout', type=int, required=True, help='Number of output images')\n",
    "    parser.add_argument('--output', type=str, default='./output/', help='Output folder')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    generate_images(args.input, args.out_dims[0], args.output, args.nout)\n",
    "\n",
    "\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee885b-3588-4e8a-b50e-38398799a77f",
   "metadata": {},
   "source": [
    "## DeepLearning Code to Identify the object in the generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143c7af4-9623-4447-a5cc-a3722de42c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 20:53:24.878104: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 20:53:24.922677: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 20:53:24.923401: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 20:53:25.668056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolo.h5\")) # Downloading the YOLO model \n",
    "detector.loadModel()\n",
    "\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"output_0.png\"), output_image_path=os.path.join(execution_path , \"image_new.png\")) # Replace 'image.jpg' with your image path\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28ccca3-0620-4168-a13c-81de430cb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 20:56:46.302201: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 20:56:46.347946: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 20:56:46.348689: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 20:56:47.096393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path, \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path, \"output_0.png\"), output_image_path=os.path.join(execution_path, \"image_new.png\"))\n",
    "\n",
    "#Detections in a variable\n",
    "detected_objects = []\n",
    "\n",
    "for eachObject in detections:\n",
    "    object_info = {\n",
    "        \"name\": eachObject[\"name\"],\n",
    "        \"percentage_probability\": eachObject[\"percentage_probability\"],\n",
    "        \"box_points\": eachObject[\"box_points\"]\n",
    "    }\n",
    "    detected_objects.append(object_info)\n",
    "\n",
    "# Manipulating the variable as needed\n",
    "for object_info in detected_objects:\n",
    "    print(object_info[\"name\"], \" : \", object_info[\"percentage_probability\"], \" : \", object_info[\"box_points\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e183d332-3799-4132-8318-db283cee5c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 329 images belonging to 4 classes.\n",
      "Found 80 images belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 17s 1s/step - loss: 10.4349 - accuracy: 0.3070 - val_loss: 1.0200 - val_accuracy: 0.5125\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 20s 2s/step - loss: 0.9043 - accuracy: 0.5836 - val_loss: 0.6367 - val_accuracy: 0.7750\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.5180 - accuracy: 0.7629 - val_loss: 0.5228 - val_accuracy: 0.7625\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 23s 2s/step - loss: 0.3627 - accuracy: 0.7994 - val_loss: 0.3862 - val_accuracy: 0.7875\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.2974 - accuracy: 0.8571 - val_loss: 0.3814 - val_accuracy: 0.8250\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 21s 2s/step - loss: 0.2469 - accuracy: 0.8815 - val_loss: 0.4885 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 22s 2s/step - loss: 0.2461 - accuracy: 0.8784 - val_loss: 0.4122 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 21s 2s/step - loss: 0.2059 - accuracy: 0.9149 - val_loss: 0.4581 - val_accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 20s 2s/step - loss: 0.1832 - accuracy: 0.9240 - val_loss: 0.4281 - val_accuracy: 0.7375\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 21s 2s/step - loss: 0.1464 - accuracy: 0.9210 - val_loss: 0.4433 - val_accuracy: 0.8250\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Predicted shape: unknown\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np  # Import numpy library\n",
    "\n",
    "#Image size and number of classes\n",
    "img_size = (256, 256)  \n",
    "num_classes = 4  \n",
    "\n",
    "# Loading training data using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Normalize and split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"training_set\",\n",
    "    target_size=img_size,\n",
    "    batch_size=32,  \n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    \"training_set\",\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Defining the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=img_size + (3,)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  \n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Loading and pre-processing the final image\n",
    "img = tf.keras.preprocessing.image.load_img(\"gear1.png\", target_size=img_size)\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)  \n",
    "x /= 255.0  \n",
    "\n",
    "# Predicting the class of the image\n",
    "predictions = model.predict(x)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "predicted_shape = train_generator.class_indices.get(predicted_class, \"unknown\")\n",
    "\n",
    "#Prediction\n",
    "print(f\"Predicted shape: {predicted_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a030a9d-6dea-455e-b961-637c7740cbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
